**Note : The Augmentation scripts are present inside bin->augmentation**

# TSDiff: An Unconditional Diffusion Model for Time Series

[![preprint](https://img.shields.io/static/v1?label=arXiv&message=2307.11494&color=B31B1B)](https://arxiv.org/abs/2307.11494)
[![License: MIT](https://img.shields.io/badge/License-Apache--2.0-yellow.svg)](https://opensource.org/licenses/Apache-2.0)
[![Venue:ICML 2023](https://img.shields.io/badge/Venue-NeurIPS%202023-007CFF)](https://neurips.cc/)

<p align="center">
  <img src="assets/overview.png" width="100%">
  <br />
  <span>Fig. 1: An overview of TSDiff’s use cases. <b>Predict:</b> By utilizing observation self-guidance, TSDiff can be
conditioned during inference to perform predictive tasks such as forecasting. <b>Refine:</b> Predictions
of base forecasters can be improved by leveraging the implicit probability density of TSDiff.
<b>Synthesize:</b> Realistic samples generated by TSDiff can be used to train downstream forecasters achieving good
performance on real test data.</span>
</p>

---

This repository contains the official implementation of the NeurIPS 2023 paper [_Predict, Refine, Synthesize: Self-Guiding Diffusion Models for Probabilistic Time Series Forecasting_](https://arxiv.org/abs/2307.11494). In this paper, we propose _TSDiff_, an unconditional diffusion model for time series. Our proposed self-guidance mechanism enables conditioning TSDiff for downstream tasks during inference, without requiring auxiliary networks or altering the training procedure. Furthermore, our refinement scheme leverages the implicit density learned by the diffusion model to iteratively refine the predictions of base forecasters. Finally, we demonstrate the high quality of the synthetic time series by training downstrain models solely on generated data and introducing the _Linear Predictive Score (LPS)_.

<p align="center">
  <img src="assets/forecasts.png" width="60%">
  <br />
  <span>Fig. 2: Example forecasts generated by TSDiff-Q for
time series in Electricity, KDDCup, and Exchange — three datasets with different frequencies and/or prediction lengths.</span>
</p>

## Installation

TSDiff requires Python 3.8 or higher.

- Create a conda environment (optional, but recommended).

```sh
conda create --name tsdiff --yes python=3.8 && conda activate tsdiff
```

- Install this package.

```sh
pip install --editable "."
```

## BibTeX

If you find this repository or the ideas presented in our paper useful, please consider citing.

```
@inproceedings{kollovieh2023predict,
 author    = {Kollovieh, Marcel and Ansari, Abdul Fatir and Bohlke-Schneider, Michael and Zschiegner, Jasper and Wang, Hao and Wang, Yuyang},
 title     = {Predict, Refine, Synthesize: Self-Guiding Diffusion Models for Probabilistic Time Series Forecasting},
 booktitle = {Advances in Neural Information Processing Systems},
 year      = {2023}
}
```

## Security

See [CONTRIBUTING](CONTRIBUTING.md#security-issue-notifications) for more information.

## License

This project is licensed under the Apache-2.0 License.
